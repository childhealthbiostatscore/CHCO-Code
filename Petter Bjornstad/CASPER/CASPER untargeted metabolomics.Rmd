---
title: "CASPER Untargeted Metabolomics"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,dpi = 600)
knitr::opts_knit$set(root.dir = "/media/tim/Work/Petter Bjornstad/Metabolomics")
library(arsenal)
library(skimr)
library(knitr)
library(mixOmics)
library(limma)
library(tidyverse)
library(haven)
library(psych)
library(pheatmap)
library(pander)
library(pheatmap)
library(pROC)
library(boot)
set.seed(1017)
```

```{r data,include=FALSE}
# Import data
raw_data <- read.csv("./Raw data/2020-03-20 Bjornstad discovery mode results jrh v2.csv",
                     stringsAsFactors=F,na.strings = "")
samples <- read.csv("./Clean data/KNN_serum.csv_sampledata.csv")
samples$X <- NULL
# Transpose
compounds <- 
  paste("W",raw_data$Molecular.Weight,raw_data$RT..min.,sep="_")
df <- raw_data %>% dplyr::select(CS.01:RH.47.L) %>% t()
colnames(df) <- compounds
df <- as.data.frame(df)
# Sample data
df$ID <- sub("\\.","-",sub(".L","",rownames(df)))
df <- left_join(df,samples,by = "ID")
# Outcome 
df$group <- factor(df$group,levels = c(1,4),labels = c("T1D","Control"))
# SAS data
sas <- read_sas("./Raw data/casperheir_for_laura.sas7bdat")
df <- left_join(df,by = "ID",
                sas[,c("ID","kidney_GFR","medullary_GFR","cortex_GFR",
                       "M_I_kg_GC","M_I_leankg_GC","FOSC_Cortex" ,"FOSC_Medullary","FOSC_Kidney")])
# Add NGAL, KIM-1, IL-18, YKL-40, MCP-1, etc.
tubular = read.csv("./Clean data/tubularinjury.csv",stringsAsFactors = F)
df = left_join(df,tubular[,c("ID","KIM1","NGAL","MCP1","logYKL40","logIL18")],by = "ID")
# Reorganize
df <- df %>% dplyr::select(ID:logIL18,everything())
# Delete SAS data
rm(sas)
```

# Preprocessing

```{r preprocessing}
# Check for samples missing > 80% of compounds, remove them
missing <- 
  which(rowSums(is.na(df[,11:ncol(df)])) / length(11:ncol(df)) > 0.8)
if (length(missing)>0){df <- df[-missing,]}
# Same for 0 instead of NA - none
missing0 <- 
  which(rowSums(df[,11:ncol(df)] == 0) / length(11:ncol(df)) > 0.8)
```

Removed `r length(missing)` samples missing > 80% of compounds and `r length(missing0)` samples with > 80% of compounds equal to 0. 

```{r}
X <- df[,24:ncol(df)]
rownames(X) = df$ID
```

# PLS-DA

## PLS-DA Performance

```{r plsda loo,cache=TRUE}
# Group as outcome
Y <- as.factor(df$group)
# PLS-DA function
plsda_true <- plsda(X,Y,ncomp = 10)
# Check error and look at optimal number of components
perf_plsda_true <- perf(plsda_true,progressBar=FALSE, auc=TRUE,
                        validation = "loo")
plot(perf_plsda_true,
     col = color.mixo(5:7), sd = TRUE, legend.position = "horizontal")
# The performance plot looks a little bit strange, but it appears the 2 components is the best option
auc_true1 <- as.numeric(perf_plsda_true$auc$comp1["AUC.mean"])
auc_true2 <- as.numeric(perf_plsda_true$auc$comp2["AUC.mean"])
```

```{r cache=TRUE,warning=FALSE}
# Bootstrap AUC
plsda_fun = function(data,i){
  df = data[i, ]
  pls = plsda(df[,-1],df[,"Y"],ncomp = 2)
  perf = perf(pls,validation = 'Mfold', folds = 5,progressBar = FALSE, 
                  nrepeat = 10, dist = 'max.dist',auc=TRUE)
  auc = cbind(perf$auc$comp1["AUC.mean"],perf$auc$comp2["AUC.mean"])
  colnames(auc) = c("comp1","comp2")
  auc
}
df_boot = cbind(Y,X)
# First column in b$t is component 1, second is component 2
b = boot(df_boot,plsda_fun,1000)
# CIs
bci1 = boot.ci(b,index = 1,type = "perc")
bci2 = boot.ci(b,index = 2,type = "perc")
```

Performance was evaluated for 10 PLS-DA components using leave one out (LOO) cross-validation (CV). Two components resulted in the lowest overall classification error. For component 1, overall error rate was `r round(perf_plsda_true$error.rate.all$overall$centroids.dist[1],3)` with AUC of `r auc_true1` (95% CI: `r paste0(bci1$percent[4],", ",bci1$percent[5])`). For component 2, overall error rate was `r round(perf_plsda_true$error.rate.all$overall$centroids.dist[2],3)` with AUC of `r auc_true2` (95% CI: `r paste0(bci2$percent[4],", ",bci2$percent[5])`).

```{r plsda results}
p = plotIndiv(plsda_true,comp = c(1,2),ellipse = T,legend = F,ind.names = F,
              title = "")
ggplot(p$df,aes(x=x,y=y,color = group)) + 
  geom_point(color = p$df$col,aes(shape = group)) + 
  xlab(p$graph$labels$x) + ylab(p$graph$labels$y) +
  theme_bw() +
  geom_path(data = p$df.ellipse,aes(x = Col1,y = Col2),inherit.aes = F,
            color = levels(factor(p$df$col))[1]) +
  geom_path(data = p$df.ellipse,aes(x = Col3,y = Col4),inherit.aes = F,
            color = levels(factor(p$df$col))[2]) +
  theme(axis.text=element_blank(),axis.ticks = element_blank(),
        legend.position = "none") +
  scale_x_reverse()
```

## Permutation Testing

```{r permutation testing,cache=TRUE,include=FALSE}
# Permutation testing
n_perm <- 1000
aucs = lapply(1:n_perm,function(i){
  set.seed(1+i)
  Y <- sample(df$group,replace = F)
  plsda_res <- plsda(X,Y,ncomp = 2)
  perf_plsda <- perf(plsda_res,progressBar=FALSE, auc=TRUE,
                     validation = "loo")
  auc1 <- as.numeric(perf_plsda$auc$comp1["AUC.mean"])
  auc2 <- as.numeric(perf_plsda$auc$comp2["AUC.mean"])
  return(c(auc1,auc2))
})
aucs = as.data.frame(do.call(rbind,aucs))
```

```{r plot perms}
# Plot for each component
plot1 <- ggplot(aucs,aes(x=V1)) + 
  geom_histogram(binwidth = 0.01) + 
  geom_vline(aes(xintercept=auc_true1),color="red") + 
  theme_bw() + xlab("AUC") + ggtitle("Component 1")
plot1
plot2 <- ggplot(aucs,aes(x=V2)) + 
  geom_histogram(binwidth = 0.01) + 
  geom_vline(aes(xintercept=auc_true2),color="red") + 
  theme_bw() + xlab("AUC") + ggtitle("Component 2")
plot2
# Permutation p values
p1 <- (sum(aucs$V1 > auc_true1) + 1) / (length(aucs$V1) + 1)
p2 <- (sum(aucs$V2 > auc_true2) + 1) / (length(aucs$V2) + 1)
```

Group labels were permuted `r n_perm` times. Two component PLS-DA was run for each permutation and AUC was calculated using LOO CV. Red line indicates the AUC calculated for non-permuted data, and the gray histogram represents the null distribution of AUC. So, the permutation-based p value for AUC of component 1 is `r format.pval(p1,eps = 0.001)` and is `r  format.pval(p2,eps = 0.001)` for component 2. In other words, it's likely that PLS-DA is finding genuine differences between group 1 and group 4 and the AUC is not purely due to overfitting.

## Loadings

List of top 20 identified compounds in terms of discrimination for component 1 of the PLS-DA:

```{r comp1 vars}
var1 <- selectVar(plsda_true,comp = 1)$name
names <- raw_data$Name[match(var1,compounds)]
top20_pls <- var1[which(!is.na(names))[1:20]]
kable(head(names[!is.na(names)],20),col.names = "Compound Name")
```

List of top 20 identified compounds in terms of discrimination for component 2:

```{r comp2 vars}
var2 <- selectVar(plsda_true,comp = 2)$name
names <- raw_data$Name[match(var2,compounds)]
kable(head(names[!is.na(names)],20),col.names = "Compound Name")
```

# Moderated t tests

Top 20 identified metabolites that are significantly different between groups. P values adjusted using the FDR method. The reference group here is T1D, so negative logFC values indicate that the metabolite was lower in controls (and positive values indicate it was higher).

```{r message=FALSE}
# Design matrix - 0 and 1 for CAC progression
design <- model.matrix(~factor(group),df)
# Linear model - X is "expression" matrix (samples in columns)
# Log base 2 transformation
fit <- lmFit(log(t(X),base = 2),design)
fit <- eBayes(fit)
# Results
results <- topTable(fit,coef = "factor(group)Control",number = ncol(X),
                    adjust.method = "BH")
results$m.z <- sapply(strsplit(rownames(results),"_"),"[[",2)
results$p.value <- results$P.Value
results$t.score <- results$t
results$Compound <- raw_data$Name[match(rownames(results),compounds)]
top20 <- rownames(results[!is.na(results$Compound),])[1:20]
# These results must then be uploaded to MetaboAnalyst for compound identification.
write.csv(results[,c("m.z","p.value","t.score")],na="",row.names = F,
          file = "./Clean data/untargeted_metaboanalyst.csv")
write.csv(results[,c("m.z","logFC","p.value","t.score")],
          na="",row.names = F,
          file = "./Clean data/untargeted_results.csv")
# table
results <- 
  results[!is.na(results$Compound),
          c("Compound","m.z","logFC","t.score","p.value","adj.P.Val")]
kable(head(results,20),row.names = F)
```

# Correlations for the Metabolites by Moderated t test

```{r}
vars = c("M_I_kg_GC","M_I_leankg_GC","body_fat","screen_bmi_percentile","rpf","acr_mean","gfr","kidney_GFR","medullary_GFR","cortex_GFR","FOSC_Cortex","FOSC_Medullary","FOSC_Kidney")
varnames = c("M/I per kg","M/I per lean kg","Body fat","BMI %ile","RPF","Mean ACR","GFR","Whole-kidney RO2:GFR","Medullary RO2:GFR","Cortical RO2:GFR","Cortex FSOC","Medullary FSOC","Kidney FSOC")
intersection = intersect(top20,top20_pls)
```

### Correlations

```{r}
c = corr.test(X[,intersection],df[,vars],method = "spearman",adjust = "fdr")
rownames(c$r) <- raw_data$Name[match(rownames(c$r),compounds)]
colnames(c$r) <- varnames

rownames(c$p) <- raw_data$Name[match(rownames(c$p),compounds)]
colnames(c$p) <- varnames

emphasize.strong.cells(which(c$p[!duplicated(rownames(c$r)) & rownames(c$r) != "920863",] < 0.05, arr.ind = TRUE))
pander(round(c$r[!duplicated(rownames(c$r)) & rownames(c$r) != "920863",],2))
```

### Heatmap

```{r}
p = c$r[!duplicated(rownames(c$r)) & rownames(c$r) != "920863",]
pheatmap(p,legend = F)
```
