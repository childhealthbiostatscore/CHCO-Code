---
title: "Predicting GFR From Renal Imaging"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r setup, include=FALSE}
library(arsenal)
library(tidyverse)
library(performance)
library(knitr)
library(GGally)
library(glmnet)
library(broom)
knitr::opts_chunk$set(echo = FALSE)
if(Sys.info()["sysname"] == "Windows"){
  home_dir = "B:/Projects"
} else if (Sys.info()["sysname"] == "Linux"){
  home_dir = "~/UCD/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/Peds Endo/Petter Bjornstad/Renal Imaging"
} else if (Sys.info()["sysname"] == "Darwin"){
  home_dir = "/Volumes/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/Peds Endo/Petter Bjornstad/Renal Imaging"
}
knitr::opts_knit$set(root.dir = home_dir)
```

```{r}
# Import
df = read.csv("./Data_Clean/analysis_dataset.csv")
# Outcomes and predictors
outcomes = c('igfr','igfr_ab','eGFR_schwartz')
pred = c('hr_mri_sr','hr_mri_rv_sr','hr_mri_la_sr','hr_mri_lv_sr','peak_flow',
         'rbf_avg','rbf_avg_vein','rbf_peak','rbf_peak_vein','rbv_peak','rbv_peak_vein')
# Calculate eGFR from Pottel
# alpha=0.5;
# if age_current=11 then qcr=0.53;
# if age_current=12 then qcr=0.57;
# if age_current=13 then qcr=0.59;
# if age_current=14 then qcr=0.61;
# if age_current=15 then do; if gender=0 then qcr=0.64; if gender=1 then qcr=0.72; end;
# if age_current=16 then do; if gender=0 then qcr=0.67; if gender=1 then qcr=0.78; end;
# if age_current=17 then do; if gender=0 then qcr=0.69; if gender=1 then qcr=0.82; end;
# if age_current=18 then do; if gender=0 then qcr=0.69; if gender=1 then qcr=0.85; end;
# if age_current=19 then do; if gender=0 then qcr=0.70; if gender=1 then qcr=0.88; end;
# if age_current >=20 then do; if gender=0 then qcr=0.70; if gender=1 then qcr=0.90; end;
# 
# 
# 
# f1 = serum_creatinine/qcr;
# 
# f2 = 1-alpha;
# 
# 
# 
# f3 = cystatin_c/0.82;
# 
# eGFR_cr = 107.3 / f1;
# eGFR_comb = 107.3 / ((alpha*f1) + (f2*f3));
```

# Outcomes and Predictor Pairs

Plots on the diagonal represent the distribution of the variable.

```{r fig.height=12,fig.width=12,warning=FALSE}
ggpairs(df[,c(outcomes,pred)]) + 
  theme_bw() +
  theme(axis.line=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank()) 
```

# ElasticNet

The ElasticNet is similar to the Lasso approach for model selection, but performs better when predictors are highly correlated. To select a model, we used leave one out (LOO) cross validation (CV) to find the tuning parameter $\lambda$ that results in the lowest model error. Because $\lambda$ essentially controls how many variables are selected, common practice is to use either the model with the lowest CV error ($\lambda_{min}$), or the model with the lowest CV error within one standard error of the absolute minimum ($\lambda_{1se}$). In general, the $\lambda_{min}$ model will include more predictors but therefore risks overfitting, while the $\lambda_{1se}$ model is the most parsimonious model that still has an acceptable error level.

In the cross validation plots, the vertical dashed lines indicate these two choices of $\lambda$.

## IGFR

```{r}
# Matrices
cc = df[,c("igfr",pred)]
cc = data.matrix(cc[complete.cases(cc),])
X = cc[,pred]
Y = cc[,"igfr"]
# ElasticNet CV
cv = cv.glmnet(X,Y,nfolds = nrow(X),grouped = F)
# Get coefficients
min_coefs = coef(cv, s = "lambda.min")
min_coefs = rownames(min_coefs)[which(min_coefs != 0)]
min_coefs = min_coefs[min_coefs != "(Intercept)"]
se_coefs = coef(cv, s = "lambda.1se")
se_coefs = rownames(se_coefs)[which(se_coefs != 0)]
se_coefs = se_coefs[se_coefs != "(Intercept)"]
if(length(se_coefs)==0){se_coefs = 1}
# Plot CV
plot(cv)
```

### $\lambda_{min}$ model

```{r}
# Re-fit model
f = as.formula(paste0("igfr~",paste0(min_coefs,collapse = "+")))
m = lm(f,df)
# Results
kable(tidy(m,conf.int = T),digits = 3)
```

### $\lambda_{1se}$ model

```{r}
# Re-fit model
f = as.formula(paste0("igfr~",paste0(se_coefs,collapse = "+")))
m = lm(f,df)
# Results
kable(tidy(m,conf.int = T),digits = 3)
```

## IGFR AB

```{r}
# Matrices
cc = df[,c("igfr_ab",pred)]
cc = data.matrix(cc[complete.cases(cc),])
X = cc[,pred]
Y = cc[,"igfr_ab"]
# ElasticNet CV
cv = cv.glmnet(X,Y,nfolds = nrow(X),grouped = F)
# Get coefficients
min_coefs = coef(cv, s = "lambda.min")
min_coefs = rownames(min_coefs)[which(min_coefs != 0)]
min_coefs = min_coefs[min_coefs != "(Intercept)"]
se_coefs = coef(cv, s = "lambda.1se")
se_coefs = rownames(se_coefs)[which(se_coefs != 0)]
se_coefs = se_coefs[se_coefs != "(Intercept)"]
if(length(se_coefs)==0){se_coefs = 1}
# Plot CV
plot(cv)
```

### $\lambda_{min}$ model

```{r}
# Re-fit model
f = as.formula(paste0("igfr~",paste0(min_coefs,collapse = "+")))
m = lm(f,df)
# Results
kable(tidy(m,conf.int = T),digits = 3)
```

### $\lambda_{1se}$ model

```{r}
# Re-fit model
f = as.formula(paste0("igfr~",paste0(se_coefs,collapse = "+")))
m = lm(f,df)
# Results
kable(tidy(m,conf.int = T),digits = 3)
```

## eGFR (Schwartz)

```{r}
# Matrices
cc = df[,c("eGFR_schwartz",pred)]
cc = data.matrix(cc[complete.cases(cc),])
X = cc[,pred]
Y = cc[,"eGFR_schwartz"]
# ElasticNet CV
cv = cv.glmnet(X,Y,nfolds = nrow(X),grouped = F)
# Get coefficients
min_coefs = coef(cv, s = "lambda.min")
min_coefs = rownames(min_coefs)[which(min_coefs != 0)]
min_coefs = min_coefs[min_coefs != "(Intercept)"]
se_coefs = coef(cv, s = "lambda.1se")
se_coefs = rownames(se_coefs)[which(se_coefs != 0)]
se_coefs = se_coefs[se_coefs != "(Intercept)"]
if(length(se_coefs)==0){se_coefs = 1}
# Plot CV
plot(cv)
```

### $\lambda_{min}$ model

```{r}
# Re-fit model
f = as.formula(paste0("igfr~",paste0(min_coefs,collapse = "+")))
m = lm(f,df)
# Results
kable(tidy(m,conf.int = T),digits = 3)
```

### $\lambda_{1se}$ model

```{r}
# Re-fit model
f = as.formula(paste0("igfr~",paste0(se_coefs,collapse = "+")))
m = lm(f,df)
# Results
kable(tidy(m,conf.int = T),digits = 3)
```

## eGFR (Pottel)

Need information on participant sex.